{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deep\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics, preprocessing, linear_model\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn import  metrics#Additional scklearn functions\n",
    "  #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature46</th>\n",
       "      <th>feature47</th>\n",
       "      <th>feature48</th>\n",
       "      <th>feature49</th>\n",
       "      <th>feature50</th>\n",
       "      <th>target_bernie</th>\n",
       "      <th>target_charles</th>\n",
       "      <th>target_elizabeth</th>\n",
       "      <th>target_jordan</th>\n",
       "      <th>target_ken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>333973.000000</td>\n",
       "      <td>333973.000000</td>\n",
       "      <td>333973.000000</td>\n",
       "      <td>333973.000000</td>\n",
       "      <td>333973.000000</td>\n",
       "      <td>333973.000000</td>\n",
       "      <td>333973.000000</td>\n",
       "      <td>333973.000000</td>\n",
       "      <td>333973.000000</td>\n",
       "      <td>333973.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>333973.000000</td>\n",
       "      <td>333973.000000</td>\n",
       "      <td>333973.000000</td>\n",
       "      <td>333973.000000</td>\n",
       "      <td>333973.000000</td>\n",
       "      <td>56084.000000</td>\n",
       "      <td>56084.000000</td>\n",
       "      <td>56084.000000</td>\n",
       "      <td>56084.000000</td>\n",
       "      <td>56084.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.464556</td>\n",
       "      <td>0.455349</td>\n",
       "      <td>0.481495</td>\n",
       "      <td>0.443952</td>\n",
       "      <td>0.509341</td>\n",
       "      <td>0.487671</td>\n",
       "      <td>0.527146</td>\n",
       "      <td>0.558786</td>\n",
       "      <td>0.522584</td>\n",
       "      <td>0.467633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531598</td>\n",
       "      <td>0.521866</td>\n",
       "      <td>0.522083</td>\n",
       "      <td>0.497005</td>\n",
       "      <td>0.523741</td>\n",
       "      <td>0.499929</td>\n",
       "      <td>0.499715</td>\n",
       "      <td>0.499536</td>\n",
       "      <td>0.499358</td>\n",
       "      <td>0.499679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.133621</td>\n",
       "      <td>0.096073</td>\n",
       "      <td>0.114809</td>\n",
       "      <td>0.109714</td>\n",
       "      <td>0.112870</td>\n",
       "      <td>0.116268</td>\n",
       "      <td>0.121057</td>\n",
       "      <td>0.113075</td>\n",
       "      <td>0.103130</td>\n",
       "      <td>0.118540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105093</td>\n",
       "      <td>0.112587</td>\n",
       "      <td>0.115451</td>\n",
       "      <td>0.109530</td>\n",
       "      <td>0.105004</td>\n",
       "      <td>0.500004</td>\n",
       "      <td>0.500004</td>\n",
       "      <td>0.500004</td>\n",
       "      <td>0.500004</td>\n",
       "      <td>0.500004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.031920</td>\n",
       "      <td>0.059770</td>\n",
       "      <td>0.048270</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128640</td>\n",
       "      <td>0.008640</td>\n",
       "      <td>0.046880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.371000</td>\n",
       "      <td>0.390490</td>\n",
       "      <td>0.402560</td>\n",
       "      <td>0.370610</td>\n",
       "      <td>0.434600</td>\n",
       "      <td>0.407180</td>\n",
       "      <td>0.445440</td>\n",
       "      <td>0.485590</td>\n",
       "      <td>0.453850</td>\n",
       "      <td>0.385620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458020</td>\n",
       "      <td>0.445680</td>\n",
       "      <td>0.442750</td>\n",
       "      <td>0.423140</td>\n",
       "      <td>0.454020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.463000</td>\n",
       "      <td>0.454520</td>\n",
       "      <td>0.479000</td>\n",
       "      <td>0.443450</td>\n",
       "      <td>0.512880</td>\n",
       "      <td>0.486300</td>\n",
       "      <td>0.530320</td>\n",
       "      <td>0.564230</td>\n",
       "      <td>0.523740</td>\n",
       "      <td>0.462830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529090</td>\n",
       "      <td>0.521950</td>\n",
       "      <td>0.520690</td>\n",
       "      <td>0.498260</td>\n",
       "      <td>0.525310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.556850</td>\n",
       "      <td>0.519580</td>\n",
       "      <td>0.558270</td>\n",
       "      <td>0.516130</td>\n",
       "      <td>0.587310</td>\n",
       "      <td>0.566840</td>\n",
       "      <td>0.611450</td>\n",
       "      <td>0.637840</td>\n",
       "      <td>0.591890</td>\n",
       "      <td>0.544580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602860</td>\n",
       "      <td>0.598270</td>\n",
       "      <td>0.600380</td>\n",
       "      <td>0.572600</td>\n",
       "      <td>0.594970</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988780</td>\n",
       "      <td>0.987330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995260</td>\n",
       "      <td>0.974010</td>\n",
       "      <td>0.994580</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991090</td>\n",
       "      <td>0.980610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996730</td>\n",
       "      <td>0.998650</td>\n",
       "      <td>0.976480</td>\n",
       "      <td>0.961820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature1       feature2       feature3       feature4  \\\n",
       "count  333973.000000  333973.000000  333973.000000  333973.000000   \n",
       "mean        0.464556       0.455349       0.481495       0.443952   \n",
       "std         0.133621       0.096073       0.114809       0.109714   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.371000       0.390490       0.402560       0.370610   \n",
       "50%         0.463000       0.454520       0.479000       0.443450   \n",
       "75%         0.556850       0.519580       0.558270       0.516130   \n",
       "max         1.000000       0.988780       0.987330       1.000000   \n",
       "\n",
       "            feature5       feature6       feature7       feature8  \\\n",
       "count  333973.000000  333973.000000  333973.000000  333973.000000   \n",
       "mean        0.509341       0.487671       0.527146       0.558786   \n",
       "std         0.112870       0.116268       0.121057       0.113075   \n",
       "min         0.000000       0.003170       0.031920       0.059770   \n",
       "25%         0.434600       0.407180       0.445440       0.485590   \n",
       "50%         0.512880       0.486300       0.530320       0.564230   \n",
       "75%         0.587310       0.566840       0.611450       0.637840   \n",
       "max         0.995260       0.974010       0.994580       1.000000   \n",
       "\n",
       "            feature9      feature10      ...           feature46  \\\n",
       "count  333973.000000  333973.000000      ...       333973.000000   \n",
       "mean        0.522584       0.467633      ...            0.531598   \n",
       "std         0.103130       0.118540      ...            0.105093   \n",
       "min         0.048270       0.001360      ...            0.128640   \n",
       "25%         0.453850       0.385620      ...            0.458020   \n",
       "50%         0.523740       0.462830      ...            0.529090   \n",
       "75%         0.591890       0.544580      ...            0.602860   \n",
       "max         0.991090       0.980610      ...            0.996730   \n",
       "\n",
       "           feature47      feature48      feature49      feature50  \\\n",
       "count  333973.000000  333973.000000  333973.000000  333973.000000   \n",
       "mean        0.521866       0.522083       0.497005       0.523741   \n",
       "std         0.112587       0.115451       0.109530       0.105004   \n",
       "min         0.008640       0.046880       0.000000       0.070280   \n",
       "25%         0.445680       0.442750       0.423140       0.454020   \n",
       "50%         0.521950       0.520690       0.498260       0.525310   \n",
       "75%         0.598270       0.600380       0.572600       0.594970   \n",
       "max         0.998650       0.976480       0.961820       1.000000   \n",
       "\n",
       "       target_bernie  target_charles  target_elizabeth  target_jordan  \\\n",
       "count   56084.000000    56084.000000      56084.000000   56084.000000   \n",
       "mean        0.499929        0.499715          0.499536       0.499358   \n",
       "std         0.500004        0.500004          0.500004       0.500004   \n",
       "min         0.000000        0.000000          0.000000       0.000000   \n",
       "25%         0.000000        0.000000          0.000000       0.000000   \n",
       "50%         0.000000        0.000000          0.000000       0.000000   \n",
       "75%         1.000000        1.000000          1.000000       1.000000   \n",
       "max         1.000000        1.000000          1.000000       1.000000   \n",
       "\n",
       "         target_ken  \n",
       "count  56084.000000  \n",
       "mean       0.499679  \n",
       "std        0.500004  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Loading data...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "print(\"# Loading data...\")\n",
    "# The training data is used to train your model how to predict the targets.\n",
    "train = pd.read_csv('C:/Users/deep/Desktop/numerai_training_data.csv', header=0)\n",
    "# The tournament data is the data that Numerai uses to evaluate your model.\n",
    "tournament = pd.read_csv('C:/Users/deep/Desktop/numerai_tournament_data.csv', header=0)\n",
    "\n",
    "# The tournament data contains validation data, test data and live data.\n",
    "# Validation is used to test your model locally so we separate that.\n",
    "validation = tournament[tournament['data_type']=='validation']\n",
    "\n",
    "# There are five targets in the training data which you can choose to model using the features.\n",
    "# Numerai does not say what the features mean but that's fine; we can still build a model.\n",
    "# Here we select the bernie_target.\n",
    "train_bernie = train.drop([\n",
    "        'id', 'data_type',\n",
    "        'target_charles', 'target_elizabeth',\n",
    "        'target_jordan', 'target_ken'], axis=1)\n",
    "\n",
    "# Transform the loaded CSV data into numpy arrays\n",
    "features = [f for f in list(train_bernie) if \"feature\" in f]\n",
    "X = train_bernie[features]\n",
    "Y = train_bernie['target_bernie']\n",
    "x_prediction = validation[features]\n",
    "ids = tournament['id']\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg,useTrainCV=True, cv_folds=5, early_stopping_rounds=2):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(X.values, label=Y.values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='logloss', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(X, Y,eval_metric='logloss')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(X)\n",
    "    dtrain_predprob = alg.predict(X)\n",
    "        \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % metrics.log_loss(Y.values, dtrain_predictions))\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBRegressor(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'reg:linear',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27,\n",
    " )\n",
    "modelfit(xgb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBRegressor( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'reg:linear', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1,n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(train[predictors],train[target])\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[4,5,6],\n",
    " 'min_child_weight':[4,5,6]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBRegressor( learning_rate=0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'reg:linear', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2,n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(train[predictors],train[target])\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2b = {\n",
    " 'min_child_weight':[6,8,10,12]\n",
    "}\n",
    "gsearch2b = GridSearchCV(estimator = XGBRegressor( learning_rate=0.1, n_estimators=140, max_depth=4,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'reg:linear', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2 ,n_jobs=4,iid=False, cv=5)\n",
    "gsearch2b.fit(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfit(gsearch3.best_estimator_, train, predictors)\n",
    "gsearch2b.grid_scores_, gsearch2b.best_params_, gsearch2b.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBRegressor( learning_rate =0.1, n_estimators=140, max_depth=4,\n",
    " min_child_weight=6, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'reg:linear', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test3,n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(train[predictors],train[target])\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2 = XGBRegressor(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=4,\n",
    " min_child_weight=6,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'reg:linear',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb2, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBRegressor( learning_rate =0.1, n_estimators=177, max_depth=4,\n",
    " min_child_weight=6, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'reg:linear', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test4,n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(train[predictors],train[target])\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test5 = {\n",
    " 'subsample':[i/100.0 for i in range(75,90,5)],\n",
    " 'colsample_bytree':[i/100.0 for i in range(75,90,5)]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBRegressor( learning_rate =0.1, n_estimators=177, max_depth=4,\n",
    " min_child_weight=6, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'reg:linear', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test5,n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test6 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBRegressor( learning_rate =0.1, n_estimators=177, max_depth=4,\n",
    " min_child_weight=6, gamma=0.1, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'reg:linear', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test6,n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(train[predictors],train[target])\n",
    "gsearch6.grid_scores_, gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test7 = {\n",
    " 'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05]\n",
    "}\n",
    "gsearch7 = GridSearchCV(estimator = XGBRegressor( learning_rate =0.1, n_estimators=177, max_depth=4,\n",
    " min_child_weight=6, gamma=0.1, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'reg:linear', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test7,n_jobs=4,iid=False, cv=5)\n",
    "gsearch7.fit(train[predictors],train[target])\n",
    "gsearch7.grid_scores_, gsearch7.best_params_, gsearch7.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb3 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=4,\n",
    " min_child_weight=6,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " reg_alpha=0.005,\n",
    " objective= 'reg:linear',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb3, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb4 = XGBClassifier(\n",
    " learning_rate =0.01,\n",
    " n_estimators=5000,\n",
    " max_depth=4,\n",
    " min_child_weight=6,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " reg_alpha=0.005,\n",
    " objective= 'reg:linear',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb4, train, predictors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
